---
title: "Linear Models"
author: "krishnakanth"
date: "2/10/2021"
output:
  pdf_document: default
  word_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## loading Libraries
```{r}
library(tidyverse)
library(caret)
library(MVN)
```
## Loading data 
```{r}
Advertising <- read.csv("Advertising.csv")
head(Advertising)
```
# Model 1 : sales ~ TV + Radio
## Basic plots
```{r}
par(mfrow=c(1,2))
plot(Sales ~ TV, data = Advertising, col = "red", pch = 20, cex = 1,
     main = "Advertising: Sales vs Television")
plot(Sales ~ Radio, data = Advertising, col = "blue", pch = 20, cex = 1,
     main = "Advertising: Sales vs Radio")
```

# Plots in a single frame using feartureplot function
```{r}
# Plotting Sales vs Other variables
featurePlot(x = Advertising[ , c("TV", "Radio")], y = Advertising$Sales,col= "green")

```
## Check the normality using shapiro test
In this test
\[H_0: \text{The data is normal }\]
\[H_1: \text{The data is NOT normal }\]
If $p$ - value is < 0.001 then Reject $H_0$ otherwise accept $H_0.$
```{r}
round(shapiro.test(Advertising[,"TV"])$p.value,5)
round(shapiro.test(Advertising[,"Radio"])$p.value,5)
```
from this result we can say that data is not normal
## Linear Model
Model is
$\text{Sales}=\beta_0+\beta_1*\text{TV}+\beta_2*\text{Radio}+\epsilon,$ where $\epsilon\sim N(0,\sigma^2)$


and testing Hypothesis is given as

\[H_0: \beta_0=\beta_1=\beta_2=0\]
\[H_1: \beta_i\neq0\ \text{for some}\ i=0,1,2. \]
```{r}
mod_1 = lm(Sales ~ TV+Radio, data = Advertising)
summary(mod_1)
```
in this model, from summary we can say that null hypothesis is rejected due to pvalue is almost zero
From the summary, we can conclude that the linear model is
\[Sales=2.92110+0.0458*TV+0.1880*Radio+\epsilon\]

## MVN normality test
```{r}
par(mfrow=c(1,2))
Advertising[,c(4,1)] %>% mvn(multivariatePlot = "contour")
Advertising[,c(4,2)] %>% mvn(multivariatePlot = "contour")
```


## Plotting model with diffrent parameters
```{r}
par(mfrow=c(2,2))
plot(mod_1)
```

Inference from the plots:

- **Residuals vs Fitted:** This plot shows that residuals have non-linear patterns.  it means its not a good model.

- **Normal Q-Q plot:** This plot shows that data is not normally distributed. 

- **Scale-Location plot:** It’s also called Spread-Location plot. This plot shows if residuals are spread equally along the ranges of predictors. This is how you can check the assumption of equal variance . It’s good if you see a horizontal line with equally (randomly) spread points.

- **Resudual vs Leverage:** This plot helps us to find influential cases (i.e., subjects) if any.


# Model 2 : sales ~ TV + Radio + TV*Radio

## create new column Tv_Radio
```{r}
Advertising <- Advertising %>% 
  mutate(TV_Radio = Advertising$TV *Advertising$Radio)
head(Advertising)
```

## Basic plots
```{r}
par(mfrow=c(1,3))
plot(Sales ~ TV, data = Advertising, col = "red", pch = 20, cex = 1,
     main = "Advertising: Sales vs Television")
plot(Sales ~ Radio, data = Advertising, col = "blue", pch = 20, cex = 1,
     main = "Advertising: Sales vs Radio")
plot(Sales ~ TV_Radio, data = Advertising, col = "green", pch = 20, cex = 1,
     main = "Advertising: Sales vs Radio * Television")
```

# Plots in a single frame using feartureplot function
```{r}
# Plotting Sales vs Other variables
featurePlot(x = Advertising[ , c("TV", "Radio","TV_Radio")], y = Advertising$Sales,col= "blue")

```
## Check the normality using shapiro test
In this test
\[H_0: \text{The data is normal }\]
\[H_1: \text{The data is NOT normal }\]
If $p$ - value is < 0.001 then Reject $H_0$ otherwise accept $H_0.$
```{r}
round(shapiro.test(Advertising[,"TV"])$p.value,5)
round(shapiro.test(Advertising[,"Radio"])$p.value,5)
round(shapiro.test(Advertising[,"TV_Radio"])$p.value,5)
```
from this result we can say that data is not normal

## MVN normality test
```{r}
par(mfrow=c(1,3))
Advertising[,c(4,1)] %>% mvn(multivariatePlot = "contour")
Advertising[,c(4,2)] %>% mvn(multivariatePlot = "contour")
Advertising[,c(4,5)] %>% mvn(multivariatePlot = "contour")
```
## Linear Model
Model is
$\text{Sales}=\beta_0+\beta_1*\text{TV}+\beta_2*\text{Radio}+\beta_3*\text{TV*Radio}+\epsilon,$ where $\epsilon\sim N(0,\sigma^2)$


and testing Hypothesis is given as

\[H_0: \beta_0=\beta_1=\beta_2=\beta_3=0\]
\[H_1: \beta_i\neq0\ \text{for some}\ i=0,1,2,3. \]
```{r}
mod_2 = lm(Sales ~ TV+Radio+TV_Radio, data = Advertising)
summary(mod_2)
```
in this model, from summary we can say that null hypothesis is rejected due to pvalue is almost zero
From the summary, we can conclude that the linear model is
\[Sales=0.006750+0.0458*TV+0.00288*Radio+0.001860*(TV*Radio)+\epsilon\]


#Plotting model with diffrent parameters
```{r}
par(mfrow=c(2,2))
plot(mod_1)
```

Inference from the plots:

- **Residuals vs Fitted:** This plot shows that residuals have non-linear patterns.  it means its not a good model.

- **Normal Q-Q plot:** This plot shows that data is not normally distributed. 

- **Scale-Location plot:** It’s also called Spread-Location plot. This plot shows if residuals are spread equally along the ranges of predictors. This is how you can check the assumption of equal variance . It’s good if you see a horizontal line with equally (randomly) spread points.

- **Resudual vs Leverage:** This plot helps us to find influential cases (i.e., subjects) if any.